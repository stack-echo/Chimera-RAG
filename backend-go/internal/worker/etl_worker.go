package worker

import (
	"context"
	"io"
	"log"
	"time"

	pb "Chimera-RAG/backend-go/api/rag/v1"
	"Chimera-RAG/backend-go/internal/data"

	"github.com/google/uuid"
	"github.com/minio/minio-go/v7"
	"github.com/qdrant/go-client/qdrant"
)

// ETLWorker è´Ÿè´£ä» Redis æ‹¿ä»»åŠ¡ï¼Œå¹¶æ‰§è¡Œ ETL æµç¨‹
type ETLWorker struct {
	data       *data.Data
	grpcClient pb.LLMServiceClient
}

func NewETLWorker(data *data.Data, client pb.LLMServiceClient) *ETLWorker {
	return &ETLWorker{
		data:       data,
		grpcClient: client,
	}
}

// Start å¯åŠ¨ Worker (é˜»å¡è¿è¡Œ)
func (w *ETLWorker) Start(ctx context.Context, numWorkers int) {
	log.Printf("ğŸš€ å¯åŠ¨ %d ä¸ª ETL Workerï¼Œå¼€å§‹ç›‘å¬é˜Ÿåˆ— task:parse_pdf...", numWorkers)

	for i := 0; i < numWorkers; i++ {
		go w.processLoop(ctx, i)
	}
}

func (w *ETLWorker) processLoop(ctx context.Context, workerID int) {
	for {
		select {
		case <-ctx.Done():
			return
		default:
			// 1. é˜»å¡å¼è·å–ä»»åŠ¡ (BLPOP)
			result, err := w.data.Redis.BLPop(ctx, 0*time.Second, "task:parse_pdf").Result()
			if err != nil {
				// Redis å¶å°”è¿æ¥è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œä¸è¦ panic
				log.Printf("[Worker-%d] ç­‰å¾…ä»»åŠ¡ä¸­... (%v)", workerID, err)
				time.Sleep(3 * time.Second)
				continue
			}

			fileName := result[1]
			log.Printf("[Worker-%d] æ”¶åˆ°ä»»åŠ¡: %s", workerID, fileName)

			// 2. æ‰§è¡Œå…·ä½“å¤„ç†é€»è¾‘
			err = w.processFile(ctx, fileName)
			if err != nil {
				log.Printf("[Worker-%d] âŒ å¤„ç†å¤±è´¥: %s, é”™è¯¯: %v", workerID, fileName, err)
			} else {
				log.Printf("[Worker-%d] âœ… å¤„ç†å®Œæˆ: %s", workerID, fileName)
			}
		}
	}
}

// processFile å•ä¸ªæ–‡ä»¶çš„ ETL æµç¨‹
func (w *ETLWorker) processFile(ctx context.Context, fileName string) error {
	// A. ä» MinIO è·å–æ–‡ä»¶æµ
	obj, err := w.data.Minio.GetObject(ctx, "chimera-docs", fileName, minio.GetObjectOptions{})
	if err != nil {
		return err
	}
	defer obj.Close()

	// è¯»å–æ–‡ä»¶æ‰€æœ‰å­—èŠ‚ (æ³¨æ„å†…å­˜å®‰å…¨ï¼Œå¤§æ–‡ä»¶è¦åˆ†ç‰‡ï¼Œä½†Demoæ¼”ç¤ºå…ˆç›´æ¥è¯»)
	fileBytes, err := io.ReadAll(obj)
	if err != nil {
		return err
	}

	// B. è°ƒç”¨ Python è¿›è¡Œ è§£æ+åˆ‡ç‰‡+å‘é‡åŒ–
	log.Printf("ğŸ“¡ å‘é€ PDF ç»™ Python è¿›è¡Œæ·±åº¦è§£æ: %s", fileName)
	parseResp, err := w.grpcClient.ParseAndEmbed(ctx, &pb.ParseRequest{
		FileContent: fileBytes,
		FileName:    fileName,
	})
	if err != nil {
		return err
	}

	// C. æ‰¹é‡å­˜å…¥ Qdrant
	points := make([]*qdrant.PointStruct, 0, len(parseResp.Chunks))

	for i, chunk := range parseResp.Chunks {
		pointID := uuid.New().String()

		// æ„é€  Payload (å…ƒæ•°æ®)
		// è¿™äº›æ•°æ®å°±æ˜¯ä»¥åæ£€ç´¢å›æ¥ç»™ DeepSeek çœ‹çš„â€œèƒŒæ™¯çŸ¥è¯†â€
		payloadMap := map[string]interface{}{
			"filename":    fileName,
			"content":     chunk.Content,    // å­˜æ­£æ–‡ï¼
			"page_number": chunk.PageNumber, // å­˜é¡µç ï¼
			"chunk_index": i,
		}

		points = append(points, &qdrant.PointStruct{
			Id:      qdrant.NewIDUUID(pointID),
			Vectors: qdrant.NewVectors(chunk.Vector...),
			Payload: qdrant.NewValueMap(payloadMap),
		})
	}

	// æ‰¹é‡å†™å…¥ (Batch Upsert)
	// çœŸå®åœºæ™¯å»ºè®®åˆ†æ‰¹ï¼Œæ¯æ¬¡ 100 ä¸ª
	if len(points) > 0 {
		_, err = w.data.Qdrant.Upsert(ctx, &qdrant.UpsertPoints{
			CollectionName: "chimera_docs",
			Points:         points,
		})
		if err != nil {
			return err
		}
	}

	log.Printf("âœ… ETL å®Œæˆ: %s ç”Ÿæˆäº† %d ä¸ªå‘é‡åˆ‡ç‰‡", fileName, len(points))
	return nil
}
