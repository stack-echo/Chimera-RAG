import sys
import os
import logging

# ç¡®ä¿èƒ½å¯¼å…¥ rpc ç›®å½•
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'rpc'))

import rag_service_pb2
import rag_service_pb2_grpc

# å¼•å…¥æ ¸å¿ƒç»„ä»¶
from core.llm import LLMClient
from core.embedding import EmbeddingModel
from tools.pdf_parser import PDFParser

class ChimeraLLMService(rag_service_pb2_grpc.LLMServiceServicer):
    def __init__(self):
        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.llm = LLMClient()
        # é¢„åŠ è½½ Embedding æ¨¡å‹
        EmbeddingModel.get_instance()

    # ----------------------------------------------------------------
    # 1. æ ¸å¿ƒé—®ç­”æ¥å£ (Stream)
    # ----------------------------------------------------------------
    def AskStream(self, request, context):
        """
        æ¥æ”¶ Go ä¼ æ¥çš„ Promptï¼Œæµå¼è¿”å› LLM çš„å›ç­”
        """
        logging.info(f"[LLM] æ”¶åˆ°æé—®è¯·æ±‚ (é•¿åº¦: {len(request.query)} chars)...")

        # ğŸ”¥ v0.3.5 å…³é”®ç‚¹ï¼šSystem Prompt
        # åœ¨è¿™é‡Œå¼ºåˆ¶è¦æ±‚ LLM ä½¿ç”¨ <<æ–‡ä»¶å|é¡µç >> çš„æ ¼å¼
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘ç ”åŠ©æ‰‹ (Chimera-RAG)ã€‚è¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚

        ã€é‡è¦å›å¤è§„åˆ™ã€‘
        1. å¿…é¡»ä¸¥æ ¼åŸºäºä¸Šä¸‹æ–‡å›ç­”ï¼Œä¸è¦ç¼–é€ äº‹å®ã€‚
        2. å¼•ç”¨æ ¼å¼ï¼šå½“å¼•ç”¨ä¸Šä¸‹æ–‡å†…å®¹æ—¶ï¼Œå¿…é¡»åœ¨å¥å°¾åŠ ä¸Šæ¥æºæ ‡è®°ã€‚
           æ ¼å¼ä¸ºï¼š<<æ–‡ä»¶å|é¡µç >>
           ä¾‹å¦‚ï¼š"...è¿™ä¸€ç»“è®ºå¾—åˆ°äº†å®éªŒéªŒè¯<<research.pdf|4>>ã€‚"
        3. å¦‚æœä¸Šä¸‹æ–‡é‡Œæ²¡æœ‰ç­”æ¡ˆï¼Œè¯·è¯šå®åœ°è¯´ä¸çŸ¥é“ã€‚
        4. ä¿æŒå›ç­”ç®€æ´æ˜äº†ï¼Œä½¿ç”¨ Markdown æ ¼å¼ã€‚
        """

        # è°ƒç”¨ LLM (æµå¼)
        # request.query æ˜¯ Go æ‹¼è£…å¥½çš„ "Context + User Question"
        try:
            generator = self.llm.stream_chat(request.query, system_prompt=system_prompt)

            for text_delta in generator:
                # å°è£…æˆ gRPC å“åº”
                yield rag_service_pb2.AskResponse(answer_delta=text_delta)

        except Exception as e:
            logging.error(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            yield rag_service_pb2.AskResponse(answer_delta=f"**Error**: {str(e)}")

    # ----------------------------------------------------------------
    # 2. å‘é‡åŒ–æ¥å£
    # ----------------------------------------------------------------
    def EmbedData(self, request, context):
        text = request.text
        # è°ƒç”¨ core å±‚çš„ Embedding
        vector = EmbeddingModel.encode(text)
        return rag_service_pb2.EmbedResponse(vector=vector)

    # ----------------------------------------------------------------
    # 3. æ–‡æ¡£è§£ææ¥å£ (v0.3.0 Docling)
    # ----------------------------------------------------------------
    def ParseAndEmbed(self, request, context):
        logging.info(f"[Parse] æ”¶åˆ°æ–‡ä»¶: {request.file_name}, å¤§å°: {len(request.file_content)} bytes")

        # 1. è°ƒç”¨ Docling è§£æ (ä¼ å…¥ bytes)
        raw_chunks = PDFParser.parse_and_chunk(
            file_source=request.file_content,
            filename=request.file_name
        )

        if not raw_chunks:
             logging.warning("âš ï¸ è§£æç»“æœä¸ºç©º")
             return rag_service_pb2.ParseResponse(chunks=[])

        # 2. æ‰¹é‡å‘é‡åŒ–å¹¶ç»„è£…
        grpc_chunks = []
        for item in raw_chunks:
            # å‘é‡åŒ–
            vector = EmbeddingModel.encode(item['content'])

            grpc_chunks.append(rag_service_pb2.DocChunk(
                content=item['content'],
                vector=vector,
                page_number=item['page'] # âœ… ç¡®ä¿è¿™é‡Œé€ä¼ äº† Docling è§£æå‡ºçš„é¡µç 
            ))

        logging.info(f"[Parse] å®Œæˆ! è¿”å› {len(grpc_chunks)} ä¸ª Chunk ç»™ Go ç«¯")
        return rag_service_pb2.ParseResponse(chunks=grpc_chunks)